
import re
from typing import Any, List

import os
import pandas as pd
from torchvision import transforms
import torch
from torchvision.io.image import decode_image
from copy import deepcopy
from torch.utils.data import random_split

from datasets import Dataset, load_dataset, load_from_disk
from trl.trainer.grpo_trainer import RewardFunc
from verifiers.parsers import XMLParser
from r1_vlm.datasets.utils import preprocess_r1_dataset
from r1_vlm.environments.simple_vision_env import SimpleVisionEnv


PROMPT_TEMPLATE = [
  {
    "content": [
      {
        "image": None,
        "text": "You are a helpful assistant. You first think about the reasoning process in your mind and then provide the user with the answer.",
        "type": "text"
      }
    ],
    "role": "system"
  },
  {
    "content": [
      {
        "image": "IMAGE_PLACEHOLDER",
        "text": None,
        "type": "image"
      },
      {
        "image": None,
        "text": "Analyze the image to determine the likelihood it was generated by AI. Your answer should be a probability in the interval [0, 1]. Show your work in <think> </think> tags and return the answer in <answer> </answer> tags, for example <answer> \"0.95\" </answer>.",
        "type": "text"
      }
    ],
    "role": "user"
  },
  {
    "content": [
      {
        "image": None,
        "text": "Let me solve this step by step.\n<think>",
        "type": "text"
      }
    ],
    "role": "assistant"
  }
]


IMAGE_PLACEHOLDER = "IMAGE_PLACEHOLDER"

def _inject_images(examples):
    messages_batch = examples["messages"]
    images_batch = examples["image"]
    
    # Validate types once for the first example
    if not isinstance(messages_batch[0], list):
        raise ValueError(f"Expected a list of messages, got {type(messages_batch[0])}")
    if not isinstance(images_batch[0], PIL.Image.Image):
        raise ValueError(f"Expected a PIL image, got {type(images_batch[0])}")
    
    for messages, image in zip(messages_batch, images_batch):
        if image_size:
            image = image.resize(image_size)
        
        for message in messages:
            content = message["content"]
            [item.update({"image": image}) for item in content if item["type"] == "image" and item["image"] == IMAGE_PLACEHOLDER]
    
    return examples


class KaggleDataset(Dataset):
    def __init__(self, path_to_kaggle_dir: str, path_to_pig_images: str):
        path_to_kaggle_train_csv = os.path.join(path_to_kaggle_dir, "train.csv")
        self.path_to_kaggle_dir = path_to_kaggle_dir
        self.path_to_pig_images = path_to_pig_images
        df = pd.read_csv(path_to_kaggle_train_csv)
        self.kaggle_image_paths = df['file_name'].to_list()
        self.kaggle_labels = df['label'].to_list()
        self.num_kaggle_images = len(self.kaggle_image_paths)

        self.pig_image_paths = os.listdir(self.path_to_pig_images)
        self.num_pig_images = len(self.pig_image_paths)

        # Define transformations to apply to the images
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),  # Resize images to a common size
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize pixel values
        ])

    def __len__(self):
        return self.num_kaggle_images + self.num_pig_images


    def _get_one_item(self, idx):
        if idx < self.num_kaggle_images:
            img_path = os.path.join(self.path_to_kaggle_dir, self.kaggle_image_paths[idx])
            label = torch.tensor(int(self.kaggle_labels[idx]))
        else:
            img_path = os.path.join(self.path_to_pig_images, self.pig_image_paths[idx - self.num_kaggle_images])
            label = torch.tensor(1)
        img = decode_image(img_path, mode="RGB").float()
        image = self.transform(img)
        messages = deepcopy(PROMPT_TEMPLATE)

        return {"messages": messages, "image": image, "label": label}

    def __getitem__(self, idx):
        if isinstance(idx, int):
            return self._get_one_item(idx)
        else:
            messages = []
            images = []
            labels = []
            for i in idx:
                it = self._get_one_item(i)
                messages.append(it['messages'])
                images.append(it['image'])
                labels.append(it['label'])
            return {"messages": messages, "image": images, "label": labels}



def make_datasets(path_to_kaggle_dir, path_to_pig_images):
    full_dataset = KaggleDataset(path_to_kaggle_dir=path_to_kaggle_dir, path_to_pig_images=path_to_pig_images)
    # Define split ratios
    train_ratio = 0.8
    val_ratio = 0.1
    # test_ratio = 0.1

    # Calculate split sizes
    total_size = len(full_dataset)
    train_size = int(train_ratio * total_size)
    val_size = int(val_ratio * total_size)
    test_size = total_size - train_size - val_size  # Ensure all samples are accounted for

    # Perform the split
    # Using a generator with a manual seed ensures reproducibility
    generator = torch.Generator().manual_seed(42)
    train_dataset, val_dataset, test_dataset = random_split(
        full_dataset, [train_size, val_size, test_size], generator=generator
    )
    return train_dataset, val_dataset, test_dataset


class NISTDiscriminatorEnv(SimpleVisionEnv):
    def __init__(
        self,
        system_prompt: str = "",
        **kwargs,  # passed to the superclass
    ):
        super().__init__(system_prompt=system_prompt, **kwargs)
        self.parser = XMLParser(fields=["think", "answer"])
        self.path_to_pig_images = "/mnt/workspace/r1_vlm_try1/data/pig_images/images_generated/"
        self.path_to_kaggle_dir = "/mnt/workspace/r1_vlm_try1/data/human_vs_ai_kaggle/"
        self.path_to_saved_dataset = "/mnt/workspace/r1_vlm_try1/data/r1_vlm_nist_hf_dataset/"
    
    def get_dataset(self) -> Dataset:
        #def generator():
        #    train_dataset, val_dataset, test_dataset = make_datasets(self.path_to_kaggle_dir, self.path_to_pig_images)
        #    for i in range(len(train_dataset)):
        #        yield train_dataset[i]

        #dataset = Dataset.from_generator(generator)
        dataset = load_from_disk(self.path_to_saved_dataset)
        dataset = preprocess_r1_dataset(dataset)
        return dataset    

    def get_rubric(self, **kwargs: Any) -> List[RewardFunc]:
        def correctness_reward_func(completions, **kwargs) -> List[float]:
            
            # parse the predicted decoded message from each completion
            responses = [self.parser.parse(c[0]["content"]).answer for c in completions]
            true_label = kwargs["label"]
            
            def check_answer(response, answer):
                # the parser returns None if the answer is not found
                if response is None:
                    return 0.0
                
                try:
                    response = float(response)
                    answer = float(answer)
                except Exception as e:
                    print(f"Error in check_answer: {e}")
                    return 0.0

                return 1 - abs(response - answer)

            rewards = [check_answer(r, t) for r, t in zip(responses, true_label)]
            return rewards
        
        def format_reward_func(completions, **kwargs) -> List[float]:
            """
            Reward function that checks for proper XML formatting

            Must have think and answer fields
            """

            def check_format(text: str) -> float:
                # remove the bootstrap prompt from the text if it appears at the start
                text = text.removeprefix("Let me solve this step by step.\n")

                try:
                    # Check if the format is correct
                    regex = r"^<think>([^<]*(?:<(?!/?think>)[^<]*)*)<\/think>\n<answer>([\s\S]*?)<\/answer>$"

                    match = re.search(regex, text, re.DOTALL)

                    if match is None or len(match.groups()) != 2:
                        return 0.0
                    else:
                        return 1.0
                except Exception as e:
                    print(f"Error in format_reward_func: {e}")
                    return 0.0

            rewards = [check_format(c[0]["content"]) for c in completions]
            return rewards
        
        return [correctness_reward_func, format_reward_func]
        
